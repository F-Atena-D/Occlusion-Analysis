{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b8a320",
   "metadata": {},
   "source": [
    "# Occlusion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2457fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "# ======= Graph Support Computation ======= #\n",
    "def compute_graph_supports(adj_mat, filter_type='dual_random_walk', device=None):\n",
    "    \"\"\"\n",
    "    Compute graph supports from adjacency matrix.\n",
    "    Supports are used as input to DCRNN layers.\n",
    "\n",
    "    Args:\n",
    "        adj_mat (np.ndarray or scipy sparse): Adjacency matrix.\n",
    "        filter_type (str): 'laplacian' or 'dual_random_walk'.\n",
    "        device (torch.device): Device to load supports onto.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.FloatTensor]: List of support matrices.\n",
    "    \"\"\"\n",
    "    supports = []\n",
    "    if filter_type == 'laplacian':\n",
    "        supports.append(utils.calculate_scaled_laplacian(adj_mat, lambda_max=None))\n",
    "    elif filter_type == 'dual_random_walk':\n",
    "        supports.append(utils.calculate_random_walk_matrix(adj_mat).T)\n",
    "        supports.append(utils.calculate_random_walk_matrix(adj_mat.T).T)\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported filter type: {filter_type}')\n",
    "\n",
    "    return [torch.FloatTensor(s.toarray()).to(device) for s in supports]\n",
    "\n",
    "# ======= Device Setup ======= #\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('af12.pkl', 'rb') as f:\n",
    "    adjfn = pickle.load(f)\n",
    "with open('ag12.pkl', 'rb') as f:\n",
    "    adjgn = pickle.load(f)\n",
    "with open('at12.pkl', 'rb') as f:\n",
    "    adjtn = pickle.load(f)\n",
    "with open('atc12.pkl', 'rb') as f:\n",
    "    adjtc = pickle.load(f)\n",
    "with open('ac12.pkl', 'rb') as f:\n",
    "    adjcp = pickle.load(f)\n",
    "with open('as12.pkl', 'rb') as f:\n",
    "    adjsp = pickle.load(f)\n",
    "with open('aa12.pkl', 'rb') as f:\n",
    "    adjab = pickle.load(f)\n",
    "\n",
    "afn = [arr for sublist in adjfn for arr in sublist]\n",
    "agn = [arr for sublist in adjgn for arr in sublist]\n",
    "acp = [arr for sublist in adjcp for arr in sublist]\n",
    "asp = [arr for sublist in adjsp for arr in sublist]\n",
    "atn = [arr for sublist in adjtn for arr in sublist]\n",
    "atc = [arr for sublist in adjtc for arr in sublist]\n",
    "aab = [arr for sublist in adjab for arr in sublist]\n",
    "\n",
    "all_adjs = np.concatenate((\n",
    "    np.array(afn, dtype=np.float32),\n",
    "    np.array(agn, dtype=np.float32),\n",
    "    np.array(aab, dtype=np.float32),\n",
    "    np.array(atn, dtype=np.float32),\n",
    "    np.array(atc, dtype=np.float32),\n",
    "    np.array(acp, dtype=np.float32),\n",
    "    np.array(asp, dtype=np.float32)\n",
    "), axis=0)\n",
    "\n",
    "all_supports = []\n",
    "for i in range(len(all_adjs)):\n",
    "    supports = compute_graph_supports(np.squeeze(all_adjs[i]), filter_type='dual_random_walk', device=device)\n",
    "    all_supports.append(supports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a374de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# def classwise_occlusion_analysis(\n",
    "#     model, data_loader, adj_mat, device, \n",
    "#     compute_supports_func, filter_type, num_classes\n",
    "# ): 1\n",
    "def classwise_occlusion_analysis(\n",
    "    model, data_loader, device, supports_orig, filter_type, num_classes\n",
    "):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    num_nodes = 19\n",
    "    supports_orig = [s.to(device) for s in supports_orig]\n",
    "\n",
    "    node_importance = {cls: defaultdict(float) for cls in range(num_classes)}\n",
    "    edge_importance = {cls: defaultdict(float) for cls in range(num_classes)}\n",
    "    class_counts = defaultdict(int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_seq_len in data_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_seq_len = batch_seq_len.to(device)\n",
    "\n",
    "            outputs = model(batch_x, batch_seq_len, supports_orig)\n",
    "            preds = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "\n",
    "            for i in range(batch_x.size(0)):\n",
    "                x_sample = batch_x[i:i+1]\n",
    "                y_true = batch_y[i].item()\n",
    "                class_counts[y_true] += 1\n",
    "\n",
    "                sl = batch_seq_len[i:i+1]\n",
    "                orig_out = model(x_sample, sl, supports_orig)\n",
    "                orig_prob = torch.softmax(orig_out, dim=1)[0, y_true].item()\n",
    "\n",
    "                # --- Node Occlusion ---\n",
    "                for node in range(num_nodes):\n",
    "                    x_occ = x_sample.clone()\n",
    "                    x_occ[:, :, node, :] = 0\n",
    "                    out_occ = model(x_occ, sl, supports_orig)\n",
    "                    occ_prob = torch.softmax(out_occ, dim=1)[0, y_true].item()\n",
    "                    drop = orig_prob - occ_prob\n",
    "                    node_importance[y_true][node] += drop\n",
    "\n",
    "                # --- Edge Occlusion ---\n",
    "                for s_idx, s in enumerate(supports_orig):\n",
    "                    for src in range(num_nodes):\n",
    "                        for tgt in range(num_nodes):\n",
    "                            if s[src, tgt] != 0:\n",
    "                                s_occ = [s_.clone() for s_ in supports_orig]\n",
    "                                s_occ[s_idx][src, tgt] = 0\n",
    "                                out_occ = model(x_sample, sl, s_occ)\n",
    "                                occ_prob = torch.softmax(out_occ, dim=1)[0, y_true].item()\n",
    "                                drop = orig_prob - occ_prob\n",
    "                                edge_importance[y_true][(src, tgt)] += drop\n",
    "\n",
    "    # Normalize\n",
    "    for cls in range(num_classes):\n",
    "        if class_counts[cls] > 0:\n",
    "            for node in node_importance[cls]:\n",
    "                node_importance[cls][node] /= class_counts[cls]\n",
    "            for edge in edge_importance[cls]:\n",
    "                edge_importance[cls][edge] /= class_counts[cls]\n",
    "\n",
    "    return node_importance, edge_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model.eval()\n",
    "pre_model.to(device)\n",
    "\n",
    "node_importance = {cls: defaultdict(float) for cls in range(7)}\n",
    "edge_importance = {cls: defaultdict(float) for cls in range(7)}\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# node_imp, edge_imp = classwise_occlusion_analysis(\n",
    "#     model=pre_model,\n",
    "#     data_loader=test_loader,\n",
    "#     adj_mat=adj_mat,\n",
    "#     device=device,\n",
    "#     compute_supports_func=compute_graph_supports,\n",
    "#     filter_type='laplacian',\n",
    "#     num_classes=7\n",
    "# ) 1\n",
    "\n",
    "node_imp, edge_imp = classwise_occlusion_analysis(\n",
    "    model=pre_model,\n",
    "    data_loader=test_loader,\n",
    "    adj_mat=adj_mat,\n",
    "    device=device,\n",
    "    supports_orig=all_supports,\n",
    "    filter_type='dual_random_walk',\n",
    "    num_classes=7\n",
    ") #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "\n",
    "def get_spectral_graph_positions():\n",
    "    \"\"\"\n",
    "    # Get positions of EEG electrodes for visualizations\n",
    "    \"\"\"\n",
    "\n",
    "    # adj_mx_all = adjdata\n",
    "    # adj_mx = adj_mx_all[-1] \n",
    "\n",
    "    node_id_dict = {'EEG FP1': 0,\n",
    "                    'EEG FP2': 1,\n",
    "                    'EEG F3': 2,\n",
    "                    'EEG F4': 3,\n",
    "                    'EEG C3': 4,\n",
    "                    'EEG C4': 5,\n",
    "                    'EEG P3': 6,\n",
    "                    'EEG P4': 7,\n",
    "                    'EEG O1': 8,\n",
    "                    'EEG O2': 9,\n",
    "                    'EEG F7': 10,\n",
    "                    'EEG F8': 11,\n",
    "                    'EEG T3': 12,\n",
    "                    'EEG T4': 13,\n",
    "                    'EEG T5': 14,\n",
    "                    'EEG T6': 15,\n",
    "                    'EEG FZ': 16,\n",
    "                    'EEG CZ': 17,\n",
    "                    'EEG PZ': 18}\n",
    "\n",
    "    eeg_viz = nx.Graph()\n",
    "    # adj_mx = adj_mx_all[-1]\n",
    "    node_id_label = collections.defaultdict()\n",
    "\n",
    "    for i in range(19):\n",
    "        eeg_viz.add_node(i)\n",
    "\n",
    "    for k, v in node_id_dict.items():\n",
    "        node_id_label[v] = k\n",
    "        \n",
    "    # Add edges\n",
    "    for i in range(19):\n",
    "        for j in range(19):  # do not include self-edge in visualization\n",
    "            if i != j: \n",
    "            # and adj_mx[i, j] > 0:\n",
    "                eeg_viz.add_edge(i, j)\n",
    "\n",
    "    pos = nx.spectral_layout(eeg_viz)\n",
    "    # keep the nice shape of the electronodes on the scalp\n",
    "    pos_spec = {node: (y, -x) for (node, (x, y)) in pos.items()}\n",
    "\n",
    "    return pos_spec\n",
    "\n",
    "\n",
    "# # def draw_graph_weighted_edge(\n",
    "# #         adj_mx,\n",
    "# #         node_id_dict,\n",
    "# #         pos_spec,\n",
    "# #         is_directed,\n",
    "# #         title='',\n",
    "# #         save_dir=None,\n",
    "# #         fig_size=(\n",
    "# #             12,\n",
    "# #             8),\n",
    "# #     node_color='Red',\n",
    "# #     font_size=20,\n",
    "# #         plot_colorbar=False):\n",
    "# def draw_graph_weighted_edge(\n",
    "#         node_id_dict,\n",
    "#         pos_spec,\n",
    "#         is_directed,\n",
    "#         title='',\n",
    "#         save_dir=None,\n",
    "#         fig_size=(\n",
    "#             12,\n",
    "#             8),\n",
    "#     node_color='Red',\n",
    "#     font_size=20,\n",
    "#         plot_colorbar=False):\n",
    "#     \"\"\"\n",
    "#     Draw a graph with weighted edges\n",
    "#     Args:\n",
    "#         adj_mx: Adjacency matrix for the graph, shape (num_nodes, num_nodes)\n",
    "#         node_id_dict: dict, key is node name, value is node index\n",
    "#         pos_spec: Graph node position specs from function get_spectral_graph_positions\n",
    "#         is_directed: If True, draw directed graphs\n",
    "#         title: str, title of the figure\n",
    "#         save_dir: Dir to save the plot\n",
    "#         fig_size: figure size\n",
    "\n",
    "#     \"\"\"\n",
    "#     eeg_viz = nx.DiGraph() if is_directed else nx.Graph()\n",
    "#     node_id_label = collections.defaultdict()\n",
    "\n",
    "#     for i in range(19):\n",
    "#         eeg_viz.add_node(i)\n",
    "\n",
    "#     for k, v in node_id_dict.items():\n",
    "#         node_id_label[v] = k\n",
    "\n",
    "#     # Add edges\n",
    "#     for i in range(19):\n",
    "#         for j in range(19):  # since it's now directed\n",
    "#             if i != j:\n",
    "#                 eeg_viz.add_edge(i, j, weight=adj_mx[i, j])\n",
    "\n",
    "#     edges, weights = zip(*nx.get_edge_attributes(eeg_viz, 'weight').items())\n",
    "\n",
    "#     # Change the color scales below\n",
    "#     k = 3\n",
    "#     cmap = plt.cm.Greys(np.linspace(0, 1, (k + 1) * len(weights)))\n",
    "#     cmap = matplotlib.colors.ListedColormap(cmap[len(weights):-1:(k - 1)])\n",
    "\n",
    "#     plt.figure(figsize=fig_size)\n",
    "#     nx.draw_networkx(eeg_viz, pos_spec, labels=node_id_label, with_labels=True,\n",
    "#                      edgelist=edges, edge_color=rankdata(weights),\n",
    "#                      width=fig_size[1] / 2, edge_cmap=cmap, font_weight='bold',\n",
    "#                      node_color=node_color,\n",
    "#                      node_size=250 * (fig_size[0] + fig_size[1]),\n",
    "#                      font_color='white',\n",
    "#                      font_size=font_size)\n",
    "#     plt.title(title, fontsize=font_size)\n",
    "#     plt.axis('off')\n",
    "#     if plot_colorbar:\n",
    "#         sm = plt.cm.ScalarMappable(\n",
    "#             cmap=cmap, norm=plt.Normalize(\n",
    "#                 vmin=0, vmax=1))\n",
    "#         sm.set_array([])\n",
    "#         plt.colorbar(sm)\n",
    "#     plt.tight_layout()\n",
    "#     if save_dir is not None:\n",
    "#         plt.savefig(save_dir, dpi=300)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44b35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_importance_graph(adj_mx_data, node_importance, edge_importance, class_label='Class', figsize=(12, 8)):\n",
    "def visualize_importance_graph(node_importance, edge_importance, class_label='Class', figsize=(12, 8)):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import networkx as nx\n",
    "\n",
    "    # Load adj matrix\n",
    "    # adj_mx = adj_mx_data[2]\n",
    "    eegnodes = {'EEG FP1': 0,\n",
    "    'EEG FP2': 1,\n",
    "    'EEG F3': 2,\n",
    "    'EEG F4': 3,\n",
    "    'EEG C3': 4,\n",
    "    'EEG C4': 5,\n",
    "    'EEG P3': 6,\n",
    "    'EEG P4': 7,\n",
    "    'EEG O1': 8,\n",
    "    'EEG O2': 9,\n",
    "    'EEG F7': 10,\n",
    "    'EEG F8': 11,\n",
    "    'EEG T3': 12,\n",
    "    'EEG T4': 13,\n",
    "    'EEG T5': 14,\n",
    "    'EEG T6': 15,\n",
    "    'EEG FZ': 16,\n",
    "    'EEG CZ': 17,\n",
    "    'EEG PZ': 18}\n",
    "    # node_id_dict = {k.split(' ')[-1]: v for k, v in adj_mx_data[1].items()}\n",
    "    node_id_dict = {k.split(' ')[-1]: v for k, v in eegnodes.items()}\n",
    "    pos_spec = get_spectral_graph_positions()\n",
    "\n",
    "    # Invert the mapping: index → label\n",
    "    node_labels = {v: k for k, v in node_id_dict.items()}\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for i in range(19):\n",
    "        G.add_node(i)\n",
    "\n",
    "    for i in range(19):\n",
    "        for j in range(19):\n",
    "            if i != j: \n",
    "            # and adj_mx[i, j] > 0:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    # Normalize node and edge importances\n",
    "    node_colors = np.array([node_importance.get(i, 0.0) for i in range(19)])\n",
    "    edge_colors = np.array([edge_importance.get((i, j), 0.0) for i, j in G.edges()])\n",
    "\n",
    "    # Normalize for color mapping\n",
    "    node_vmin, node_vmax = node_colors.min(), node_colors.max()\n",
    "    edge_vmin, edge_vmax = edge_colors.min(), edge_colors.max()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    nodes = nx.draw_networkx_nodes(\n",
    "        G, pos_spec, node_color=node_colors, cmap='Reds',\n",
    "        node_size=1200, ax=ax, vmin=node_vmin, vmax=node_vmax\n",
    "    )\n",
    "    edges = nx.draw_networkx_edges(\n",
    "        G, pos_spec, edge_color=edge_colors, edge_cmap=plt.cm.Blues,\n",
    "        width=3, ax=ax, edge_vmin=edge_vmin, edge_vmax=edge_vmax\n",
    "    )\n",
    "    nx.draw_networkx_labels(G, pos_spec, labels=node_labels, font_color='black', ax=ax, font_size=12)\n",
    "    ax.set_title(f\"Importance Visualization - {class_label}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add colorbars with correct axes context\n",
    "    sm_nodes = plt.cm.ScalarMappable(cmap='Reds', norm=plt.Normalize(vmin=node_vmin, vmax=node_vmax))\n",
    "    sm_nodes.set_array([])\n",
    "    plt.colorbar(sm_nodes, ax=ax, orientation='vertical', label='Node Importance')\n",
    "\n",
    "    sm_edges = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=edge_vmin, vmax=edge_vmax))\n",
    "    sm_edges.set_array([])\n",
    "    plt.colorbar(sm_edges, ax=ax, orientation='vertical', label='Edge Importance')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = 0\n",
    "# visualize_importance_graph(adjdata, node_importance[class_id], edge_importance[class_id], class_label=f\"Class {class_id}\")\n",
    "visualize_importance_graph(node_importance[class_id], edge_importance[class_id], class_label=f\"Class {class_id}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
